# llama3_quantization
Quantize llama 3 7b using WOQ, Sped up inference on CPU
